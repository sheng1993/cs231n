{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 32, 32, 3)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 32, 32, 3)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "from cs231n.data_utils import load_CIFAR10\n",
    "\n",
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=10000):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier. These are the same steps as\n",
    "    we used for the SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode, config):\n",
    "    # Model function for CNN model\n",
    "    training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    \n",
    "    # Conv-Relu-Bn\n",
    "    conv1 = tf.layers.conv2d(name='conv1', inputs=features['X'], filters=96, kernel_size=3, strides=1, activation=tf.nn.relu,\n",
    "                            kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(), padding='same')\n",
    "    conv1bn = tf.layers.batch_normalization(name='conv1bn', inputs=conv1, training=training)\n",
    "    \n",
    "     # Maxpool\n",
    "    pool1 = tf.layers.max_pooling2d(name='pool1', inputs=conv1bn, pool_size=2, strides=2)\n",
    "    \n",
    "    # Conv-Relu-Bn\n",
    "    conv2 = tf.layers.conv2d(name='conv2', inputs=pool1, filters=192, kernel_size=3, strides=1, activation=tf.nn.relu,\n",
    "                            kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(), padding='same')\n",
    "    conv2bn = tf.layers.batch_normalization(name='conv2bn', inputs=conv2, training=training)\n",
    "    \n",
    "    # Maxpool\n",
    "    pool2 = tf.layers.max_pooling2d(name='pool2', inputs=conv2bn, pool_size=2, strides=2)                            \n",
    "    \n",
    "    \n",
    "    # Flatten\n",
    "    pool1_flatten = tf.reshape(name='pool1_flatten', tensor=pool2, shape=[-1, 8 * 8 * 192])\n",
    "    \n",
    "    # FC\n",
    "    fc1 = tf.layers.dense(name='fc1', inputs=pool1_flatten, units=192, activation=tf.nn.relu, \n",
    "                          kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    # Dropout\n",
    "    dropout1 = tf.layers.dropout(name='dropout1',\n",
    "                                  inputs=fc1, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    fc2 = tf.layers.dense(name='fc2', inputs=dropout1, units=192, activation=tf.nn.relu,\n",
    "                         kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    # Dropout\n",
    "    dropout2 = tf.layers.dropout(name='dropout2',\n",
    "                                  inputs=fc2, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    # Logits\n",
    "    logits = tf.layers.dense(name='logits', inputs=dropout2, units=10, activation=None, \n",
    "                             kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    \n",
    "    predictions = {\n",
    "        # Generate predictions\n",
    "        'classes': tf.argmax(input=logits, axis=1),\n",
    "        'probabilities': tf.nn.softmax(logits=logits, name='softmax_tensor')\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    # Loss\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=onehot_labels, logits=logits)\n",
    "    \n",
    "    # Training operation\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        learning_rate = tf.train.exponential_decay(0.001, tf.train.get_global_step(),\n",
    "                                           10000, 0.96, staircase=True)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        \n",
    "        # batch normalization in tensorflow requires this extra dependency\n",
    "        extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(extra_update_ops):\n",
    "            train_op  = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    eval_metric_ops = {\n",
    "        'accuracy': tf.metrics.accuracy(labels=labels, predictions=predictions['classes'])\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inception_module(previous):    \n",
    "    # 1x1_128 conv\n",
    "    conv1_1_128 = tf.layers.conv2d(inputs=previous, filters=64, kernel_size=1, strides=1, activation=tf.nn.relu, \n",
    "                             kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(), padding='same')\n",
    "    \n",
    "    # 1x1_64 conv\n",
    "    conv1_1_64_1 = tf.layers.conv2d(inputs=previous, filters=64, kernel_size=1, strides=1, activation=tf.nn.relu, \n",
    "                             kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(), padding='same')\n",
    "    \n",
    "    # 1x1_64 conv\n",
    "    conv1_1_64_2 = tf.layers.conv2d(inputs=previous, filters=64, kernel_size=1, strides=1, activation=tf.nn.relu, \n",
    "                             kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(), padding='same')\n",
    "    \n",
    "    # 3x3 conv\n",
    "    conv3_3 = tf.layers.conv2d(inputs=conv1_1_64_1, filters=64, kernel_size=3, strides=1, activation=tf.nn.relu, \n",
    "                             kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(), padding='same')\n",
    "    \n",
    "    # 5x5 conv\n",
    "    conv5_5 = tf.layers.conv2d(inputs=conv1_1_64_2, filters=64, kernel_size=5, strides=1, activation=tf.nn.relu, \n",
    "                             kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(), padding='same')\n",
    "    \n",
    "    # maxpooling\n",
    "    pool3_3 = tf.layers.max_pooling2d(inputs=previous, pool_size=3, strides=1, padding='same')\n",
    "    \n",
    "    # 1x1_64 conv\n",
    "    conv1_1_64_3 = tf.layers.conv2d(inputs=pool3_3, filters=64, kernel_size=1, strides=1, activation=tf.nn.relu, \n",
    "                             kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(), padding='same')\n",
    "    \n",
    "    # 28x28x480\n",
    "    return tf.concat(values=[conv1_1_128, conv3_3, conv5_5, conv1_1_64_3], axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lenet_model_fn(features, labels, mode, config):\n",
    "    # Model function for CNN model\n",
    "    training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    \n",
    "    inputs = features['X']\n",
    "    \n",
    "    # with tf.device('/cpu:0'):\n",
    "    # Conv-Relu-Bn\n",
    "    conv1 = tf.layers.conv2d(inputs=inputs, filters=256, kernel_size=3, strides=1, activation=tf.nn.relu, \n",
    "                             kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(), padding='valid')\n",
    "    conv1bn = tf.layers.batch_normalization(inputs=conv1, training=training)\n",
    "\n",
    "    # Conv-Relu-Bn\n",
    "    conv2 = tf.layers.conv2d(inputs=conv1bn, filters=256, kernel_size=3, strides=1, activation=tf.nn.relu, \n",
    "                             kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(), padding='valid')\n",
    "    conv2bn = tf.layers.batch_normalization(inputs=conv2, training=training)\n",
    "    \n",
    "    # with tf.device('/device:GPU:0'):\n",
    "    # inception module\n",
    "    inc_module = inception_module(conv2bn)\n",
    "\n",
    "    # Flatten\n",
    "    pool1_flatten = tf.reshape(name='pool1_flatten', tensor=inc_module, shape=[-1, 28*28*256])\n",
    "\n",
    "    # FC\n",
    "    fc1 = tf.layers.dense(name='fc1', inputs=pool1_flatten, units=480, activation=tf.nn.relu, \n",
    "                          kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "    # Logits\n",
    "    logits = tf.layers.dense(name='logits', inputs=fc1, units=10, activation=None, \n",
    "                                 kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "    predictions = {\n",
    "        # Generate predictions\n",
    "        'classes': tf.argmax(input=logits, axis=1),\n",
    "        'probabilities': tf.nn.softmax(logits=logits, name='softmax_tensor')\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    # Loss\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=onehot_labels, logits=logits)\n",
    "    \n",
    "    # Training operation\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        learning_rate = tf.train.exponential_decay(0.001, tf.train.get_global_step(),\n",
    "                                           10000, 0.96, staircase=True)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        \n",
    "        # batch normalization in tensorflow requires this extra dependency\n",
    "        extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(extra_update_ops):\n",
    "            train_op  = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    eval_metric_ops = {\n",
    "        'accuracy': tf.metrics.accuracy(labels=labels, predictions=predictions['classes'])\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_model_fn(features, labels, mode, config):\n",
    "    # Model function for CNN model\n",
    "    training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    \n",
    "    inputs = features['X']\n",
    "    \n",
    "    # with tf.device('/cpu:0'):\n",
    "    # Conv-Relu-Bn\n",
    "    conv1 = tf.layers.conv2d(inputs=inputs, filters=64, kernel_size=3, strides=1, activation=tf.nn.relu, \n",
    "                             kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(), padding='same')\n",
    "    conv1bn = tf.layers.batch_normalization(inputs=conv1, training=training)\n",
    "\n",
    "    # Conv-Relu-Bn\n",
    "    conv2 = tf.layers.conv2d(inputs=conv1bn, filters=64, kernel_size=3, strides=1, activation=tf.nn.relu, \n",
    "                             kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(), padding='same')\n",
    "    conv2bn = tf.layers.batch_normalization(inputs=conv2, training=training)\n",
    "                                            \n",
    "    # maxpooling\n",
    "    pooling1 = tf.layers.max_pooling2d(inputs=conv2bn, pool_size=2, strides=2)\n",
    "    \n",
    "    # Conv-Relu-Bn\n",
    "    conv3 = tf.layers.conv2d(inputs=pooling1, filters=128, kernel_size=3, strides=1, activation=tf.nn.relu, \n",
    "                             kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(), padding='same')\n",
    "    conv3bn = tf.layers.batch_normalization(inputs=conv3, training=training)             \n",
    "    \n",
    "    # Conv-Relu-Bn\n",
    "    conv4 = tf.layers.conv2d(inputs=conv3bn, filters=128, kernel_size=3, strides=1, activation=tf.nn.relu, \n",
    "                             kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(), padding='same')\n",
    "    conv4bn = tf.layers.batch_normalization(inputs=conv4, training=training)   \n",
    "                                            \n",
    "    # maxpooling\n",
    "    pooling2 = tf.layers.max_pooling2d(inputs=conv4bn, pool_size=2, strides=2)\n",
    "       \n",
    "                                            \n",
    "    # Conv-Relu-Bn\n",
    "    conv5 = tf.layers.conv2d(inputs=pooling2, filters=256, kernel_size=3, strides=1, activation=tf.nn.relu, \n",
    "                             kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(), padding='same')\n",
    "    conv5bn = tf.layers.batch_normalization(inputs=conv5, training=training)             \n",
    "    \n",
    "    # Conv-Relu-Bn\n",
    "    conv6 = tf.layers.conv2d(inputs=conv5bn, filters=256, kernel_size=3, strides=1, activation=tf.nn.relu, \n",
    "                             kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(), padding='same')\n",
    "    conv6bn = tf.layers.batch_normalization(inputs=conv6, training=training)   \n",
    "                                            \n",
    "    # maxpooling\n",
    "    pooling3 = tf.layers.max_pooling2d(inputs=conv6bn, pool_size=2, strides=2)                                            \n",
    "\n",
    "    # Flatten\n",
    "    pool1_flatten = tf.reshape(tensor=pooling3, shape=[-1, 4*4*256])\n",
    "\n",
    "    # FC\n",
    "    fc1 = tf.layers.dense(name='fc1', inputs=pool1_flatten, units=1000, activation=tf.nn.relu, \n",
    "                          kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "    # Logits\n",
    "    logits = tf.layers.dense(name='logits', inputs=fc1, units=10, activation=None, \n",
    "                                 kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "    predictions = {\n",
    "        # Generate predictions\n",
    "        'classes': tf.argmax(input=logits, axis=1),\n",
    "        'probabilities': tf.nn.softmax(logits=logits, name='softmax_tensor')\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    # Loss\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=onehot_labels, logits=logits)\n",
    "    \n",
    "    # Training operation\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        learning_rate = tf.train.exponential_decay(0.001, tf.train.get_global_step(),\n",
    "                                           10000, 0.96, staircase=True)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        \n",
    "        # batch normalization in tensorflow requires this extra dependency\n",
    "        extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(extra_update_ops):\n",
    "            train_op  = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    eval_metric_ops = {\n",
    "        'accuracy': tf.metrics.accuracy(labels=labels, predictions=predictions['classes'])\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'session_conf': log_device_placement: true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# configuration\n",
    "session_conf = tf.ConfigProto(\n",
    "    # device_count={'CPU' : 1, 'GPU' : 0},\n",
    ")\n",
    "session_conf.log_device_placement=True\n",
    "# session_conf.gpu_options.allow_growth=True\n",
    "# session_conf.gpu_options.per_process_gpu_memory_fraction=0.7\n",
    "\n",
    "run_config = tf.estimator.RunConfig()\n",
    "run_config.session_conf=session_conf\n",
    "\n",
    "# logging\n",
    "tensors_to_log = {'probabilities': 'softmax_tensor'}\n",
    "logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=100)\n",
    "\n",
    "# model function\n",
    "cnn_model = tf.estimator.Estimator(model_fn=vgg_model_fn, model_dir='E:/tmp/my_model', config=run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into E:/tmp/my_model\\model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 3.76917\n",
      "INFO:tensorflow:global_step/sec: 9.45671\n",
      "INFO:tensorflow:step = 101, loss = 1.54222 (10.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.59374\n",
      "INFO:tensorflow:step = 201, loss = 1.06099 (10.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.63239\n",
      "INFO:tensorflow:step = 301, loss = 1.22074 (10.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.53919\n",
      "INFO:tensorflow:step = 401, loss = 0.963321 (10.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.61672\n",
      "INFO:tensorflow:step = 501, loss = 0.948941 (10.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.44375\n",
      "INFO:tensorflow:step = 601, loss = 0.880274 (10.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.55071\n",
      "INFO:tensorflow:step = 701, loss = 0.731768 (10.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.42741\n",
      "INFO:tensorflow:step = 801, loss = 0.71446 (10.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.35376\n",
      "INFO:tensorflow:step = 901, loss = 0.535453 (10.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.27233\n",
      "INFO:tensorflow:step = 1001, loss = 0.585786 (10.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.30819\n",
      "INFO:tensorflow:step = 1101, loss = 0.586563 (10.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.24487\n",
      "INFO:tensorflow:step = 1201, loss = 0.39377 (10.792 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.32394\n",
      "INFO:tensorflow:step = 1301, loss = 0.423317 (10.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34093\n",
      "INFO:tensorflow:step = 1401, loss = 0.616314 (10.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34457\n",
      "INFO:tensorflow:step = 1501, loss = 0.632663 (10.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.3443\n",
      "INFO:tensorflow:step = 1601, loss = 0.601487 (10.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.32547\n",
      "INFO:tensorflow:step = 1701, loss = 0.319137 (10.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33854\n",
      "INFO:tensorflow:step = 1801, loss = 0.318343 (10.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33122\n",
      "INFO:tensorflow:step = 1901, loss = 0.291578 (10.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33512\n",
      "INFO:tensorflow:step = 2001, loss = 0.425808 (10.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33609\n",
      "INFO:tensorflow:step = 2101, loss = 0.377864 (10.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33673\n",
      "INFO:tensorflow:step = 2201, loss = 0.276118 (10.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33577\n",
      "INFO:tensorflow:step = 2301, loss = 0.217227 (10.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.24918\n",
      "INFO:tensorflow:step = 2401, loss = 0.285547 (10.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33703\n",
      "INFO:tensorflow:step = 2501, loss = 0.280269 (10.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34736\n",
      "INFO:tensorflow:step = 2601, loss = 0.16326 (10.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34167\n",
      "INFO:tensorflow:step = 2701, loss = 0.269462 (10.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34162\n",
      "INFO:tensorflow:step = 2801, loss = 0.236871 (10.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.38377\n",
      "INFO:tensorflow:step = 2901, loss = 0.273667 (10.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33107\n",
      "INFO:tensorflow:step = 3001, loss = 0.253383 (10.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.3799\n",
      "INFO:tensorflow:step = 3101, loss = 0.0849601 (10.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33288\n",
      "INFO:tensorflow:step = 3201, loss = 0.192514 (10.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33709\n",
      "INFO:tensorflow:step = 3301, loss = 0.165421 (10.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34341\n",
      "INFO:tensorflow:step = 3401, loss = 0.196449 (10.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.38962\n",
      "INFO:tensorflow:step = 3501, loss = 0.0891181 (10.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.31274\n",
      "INFO:tensorflow:step = 3601, loss = 0.0763749 (10.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34733\n",
      "INFO:tensorflow:step = 3701, loss = 0.135041 (10.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34083\n",
      "INFO:tensorflow:step = 3801, loss = 0.157943 (10.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.38567\n",
      "INFO:tensorflow:step = 3901, loss = 0.110525 (10.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.32943\n",
      "INFO:tensorflow:step = 4001, loss = 0.122306 (10.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33728\n",
      "INFO:tensorflow:step = 4101, loss = 0.0576968 (10.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.3747\n",
      "INFO:tensorflow:step = 4201, loss = 0.0732342 (10.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.3423\n",
      "INFO:tensorflow:step = 4301, loss = 0.0359978 (10.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34041\n",
      "INFO:tensorflow:step = 4401, loss = 0.206493 (10.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33244\n",
      "INFO:tensorflow:step = 4501, loss = 0.121727 (10.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.38838\n",
      "INFO:tensorflow:step = 4601, loss = 0.100235 (10.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.32714\n",
      "INFO:tensorflow:step = 4701, loss = 0.167951 (10.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.31184\n",
      "INFO:tensorflow:step = 4801, loss = 0.0969415 (10.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.3312\n",
      "INFO:tensorflow:step = 4901, loss = 0.0354755 (10.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34146\n",
      "INFO:tensorflow:step = 5001, loss = 0.112787 (10.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33387\n",
      "INFO:tensorflow:step = 5101, loss = 0.040895 (10.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34686\n",
      "INFO:tensorflow:step = 5201, loss = 0.0921577 (10.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.40771\n",
      "INFO:tensorflow:step = 5301, loss = 0.0699732 (10.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.3844\n",
      "INFO:tensorflow:step = 5401, loss = 0.0906218 (10.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33326\n",
      "INFO:tensorflow:step = 5501, loss = 0.13557 (10.714 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5593 into E:/tmp/my_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 7.19324\n",
      "INFO:tensorflow:step = 5601, loss = 0.0727568 (13.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34708\n",
      "INFO:tensorflow:step = 5701, loss = 0.0813675 (10.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34483\n",
      "INFO:tensorflow:step = 5801, loss = 0.0783947 (10.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.35535\n",
      "INFO:tensorflow:step = 5901, loss = 0.18538 (10.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34764\n",
      "INFO:tensorflow:step = 6001, loss = 0.106364 (10.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.32979\n",
      "INFO:tensorflow:step = 6101, loss = 0.0924527 (10.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33477\n",
      "INFO:tensorflow:step = 6201, loss = 0.0649308 (10.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33409\n",
      "INFO:tensorflow:step = 6301, loss = 0.0392726 (10.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33996\n",
      "INFO:tensorflow:step = 6401, loss = 0.0828476 (10.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.3344\n",
      "INFO:tensorflow:step = 6501, loss = 0.0295803 (10.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.39088\n",
      "INFO:tensorflow:step = 6601, loss = 0.01895 (10.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34231\n",
      "INFO:tensorflow:step = 6701, loss = 0.106161 (10.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.38244\n",
      "INFO:tensorflow:step = 6801, loss = 0.0697661 (10.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.3417\n",
      "INFO:tensorflow:step = 6901, loss = 0.131326 (10.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33469\n",
      "INFO:tensorflow:step = 7001, loss = 0.159189 (10.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.3896\n",
      "INFO:tensorflow:step = 7101, loss = 0.23245 (10.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.42328\n",
      "INFO:tensorflow:step = 7201, loss = 0.0431004 (10.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33999\n",
      "INFO:tensorflow:step = 7301, loss = 0.0316857 (10.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33355\n",
      "INFO:tensorflow:step = 7401, loss = 0.0315181 (10.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.42578\n",
      "INFO:tensorflow:step = 7501, loss = 0.0254742 (10.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.37446\n",
      "INFO:tensorflow:step = 7601, loss = 0.0629708 (10.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33579\n",
      "INFO:tensorflow:step = 7701, loss = 0.172721 (10.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34094\n",
      "INFO:tensorflow:step = 7801, loss = 0.0217299 (10.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33807\n",
      "INFO:tensorflow:step = 7901, loss = 0.0703137 (10.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34437\n",
      "INFO:tensorflow:step = 8001, loss = 0.028976 (10.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 8101, loss = 0.076485 (10.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33893\n",
      "INFO:tensorflow:step = 8201, loss = 0.0191821 (10.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.3333\n",
      "INFO:tensorflow:step = 8301, loss = 0.0251983 (10.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.36846\n",
      "INFO:tensorflow:step = 8401, loss = 0.0233849 (10.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34128\n",
      "INFO:tensorflow:step = 8501, loss = 0.0242617 (10.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34711\n",
      "INFO:tensorflow:step = 8601, loss = 0.0464927 (10.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34039\n",
      "INFO:tensorflow:step = 8701, loss = 0.0315238 (10.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33493\n",
      "INFO:tensorflow:step = 8801, loss = 0.0209302 (10.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33792\n",
      "INFO:tensorflow:step = 8901, loss = 0.0644755 (10.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33647\n",
      "INFO:tensorflow:step = 9001, loss = 0.035165 (10.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.37713\n",
      "INFO:tensorflow:step = 9101, loss = 0.0181501 (10.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34532\n",
      "INFO:tensorflow:step = 9201, loss = 0.0158265 (10.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33294\n",
      "INFO:tensorflow:step = 9301, loss = 0.107734 (10.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33949\n",
      "INFO:tensorflow:step = 9401, loss = 0.0311508 (10.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.31387\n",
      "INFO:tensorflow:step = 9501, loss = 0.0163926 (10.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.32452\n",
      "INFO:tensorflow:step = 9601, loss = 0.125346 (10.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.36492\n",
      "INFO:tensorflow:step = 9701, loss = 0.0276805 (10.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33884\n",
      "INFO:tensorflow:step = 9801, loss = 0.0165239 (10.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.37897\n",
      "INFO:tensorflow:step = 9901, loss = 0.130251 (10.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33821\n",
      "INFO:tensorflow:step = 10001, loss = 0.0244485 (10.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.36479\n",
      "INFO:tensorflow:step = 10101, loss = 0.026596 (10.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.37324\n",
      "INFO:tensorflow:step = 10201, loss = 0.0341739 (10.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34373\n",
      "INFO:tensorflow:step = 10301, loss = 0.0155367 (10.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33206\n",
      "INFO:tensorflow:step = 10401, loss = 0.0211258 (10.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33086\n",
      "INFO:tensorflow:step = 10501, loss = 0.0329659 (10.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33837\n",
      "INFO:tensorflow:step = 10601, loss = 0.0294605 (10.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.31474\n",
      "INFO:tensorflow:step = 10701, loss = 0.0307985 (10.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34272\n",
      "INFO:tensorflow:step = 10801, loss = 0.0201164 (10.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.3395\n",
      "INFO:tensorflow:step = 10901, loss = 0.0216524 (10.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.32932\n",
      "INFO:tensorflow:step = 11001, loss = 0.0110385 (10.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.37736\n",
      "INFO:tensorflow:step = 11101, loss = 0.0250099 (10.663 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11173 into E:/tmp/my_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 7.36925\n",
      "INFO:tensorflow:step = 11201, loss = 0.0315911 (13.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.32252\n",
      "INFO:tensorflow:step = 11301, loss = 0.120911 (10.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33282\n",
      "INFO:tensorflow:step = 11401, loss = 0.0477572 (10.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.37882\n",
      "INFO:tensorflow:step = 11501, loss = 0.00111741 (10.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33394\n",
      "INFO:tensorflow:step = 11601, loss = 0.0585669 (10.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.32598\n",
      "INFO:tensorflow:step = 11701, loss = 0.0286288 (10.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.31615\n",
      "INFO:tensorflow:step = 11801, loss = 0.0354744 (10.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.32359\n",
      "INFO:tensorflow:step = 11901, loss = 0.0325513 (10.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33287\n",
      "INFO:tensorflow:step = 12001, loss = 0.0212601 (10.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34189\n",
      "INFO:tensorflow:step = 12101, loss = 0.00894414 (10.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.36228\n",
      "INFO:tensorflow:step = 12201, loss = 0.0101004 (10.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34914\n",
      "INFO:tensorflow:step = 12301, loss = 0.0429769 (10.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33031\n",
      "INFO:tensorflow:step = 12401, loss = 0.00219561 (10.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34099\n",
      "INFO:tensorflow:step = 12501, loss = 0.0385352 (10.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33343\n",
      "INFO:tensorflow:step = 12601, loss = 0.0107437 (10.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34474\n",
      "INFO:tensorflow:step = 12701, loss = 0.00279177 (10.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33453\n",
      "INFO:tensorflow:step = 12801, loss = 0.00330653 (10.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.40523\n",
      "INFO:tensorflow:step = 12901, loss = 0.00825742 (10.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.40311\n",
      "INFO:tensorflow:step = 13001, loss = 0.0145778 (10.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.36599\n",
      "INFO:tensorflow:step = 13101, loss = 0.0417089 (10.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.338\n",
      "INFO:tensorflow:step = 13201, loss = 0.00159745 (10.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.31804\n",
      "INFO:tensorflow:step = 13301, loss = 0.0319753 (10.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33464\n",
      "INFO:tensorflow:step = 13401, loss = 0.0060207 (10.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33549\n",
      "INFO:tensorflow:step = 13501, loss = 0.0666352 (10.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33727\n",
      "INFO:tensorflow:step = 13601, loss = 0.0514004 (10.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33374\n",
      "INFO:tensorflow:step = 13701, loss = 0.0493674 (10.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.32777\n",
      "INFO:tensorflow:step = 13801, loss = 0.0472272 (10.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.35815\n",
      "INFO:tensorflow:step = 13901, loss = 0.00541698 (10.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34974\n",
      "INFO:tensorflow:step = 14001, loss = 0.00927705 (10.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33552\n",
      "INFO:tensorflow:step = 14101, loss = 0.146503 (10.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.3163\n",
      "INFO:tensorflow:step = 14201, loss = 0.0709426 (10.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34784\n",
      "INFO:tensorflow:step = 14301, loss = 0.0142496 (10.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.39812\n",
      "INFO:tensorflow:step = 14401, loss = 0.0132704 (10.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.38903\n",
      "INFO:tensorflow:step = 14501, loss = 0.0749855 (10.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.39086\n",
      "INFO:tensorflow:step = 14601, loss = 0.0207639 (10.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34538\n",
      "INFO:tensorflow:step = 14701, loss = 0.0150622 (10.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33381\n",
      "INFO:tensorflow:step = 14801, loss = 0.0706813 (10.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33396\n",
      "INFO:tensorflow:step = 14901, loss = 0.0230735 (10.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.32689\n",
      "INFO:tensorflow:step = 15001, loss = 0.0132817 (10.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33925\n",
      "INFO:tensorflow:step = 15101, loss = 0.0796571 (10.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33523\n",
      "INFO:tensorflow:step = 15201, loss = 0.00115432 (10.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.32697\n",
      "INFO:tensorflow:step = 15301, loss = 0.000300218 (10.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.30624\n",
      "INFO:tensorflow:step = 15401, loss = 0.00291978 (10.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34459\n",
      "INFO:tensorflow:step = 15501, loss = 0.0465404 (10.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.39488\n",
      "INFO:tensorflow:step = 15601, loss = 0.0238219 (10.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.43821\n",
      "INFO:tensorflow:step = 15701, loss = 0.00141704 (10.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.4044\n",
      "INFO:tensorflow:step = 15801, loss = 0.0109607 (10.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.39859\n",
      "INFO:tensorflow:step = 15901, loss = 0.00219625 (10.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.41771\n",
      "INFO:tensorflow:step = 16001, loss = 0.0247818 (10.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.43846\n",
      "INFO:tensorflow:step = 16101, loss = 0.000234736 (10.594 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 9.41115\n",
      "INFO:tensorflow:step = 16201, loss = 0.0212823 (10.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.41847\n",
      "INFO:tensorflow:step = 16301, loss = 0.000598357 (10.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.39335\n",
      "INFO:tensorflow:step = 16401, loss = 0.135013 (10.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33679\n",
      "INFO:tensorflow:step = 16501, loss = 0.0198751 (10.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.31246\n",
      "INFO:tensorflow:step = 16601, loss = 0.00124773 (10.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.35619\n",
      "INFO:tensorflow:step = 16701, loss = 0.0406598 (10.688 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16759 into E:/tmp/my_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 7.33007\n",
      "INFO:tensorflow:step = 16801, loss = 0.0450893 (13.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34411\n",
      "INFO:tensorflow:step = 16901, loss = 0.0010812 (10.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34578\n",
      "INFO:tensorflow:step = 17001, loss = 0.00110149 (10.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.36717\n",
      "INFO:tensorflow:step = 17101, loss = 0.188073 (10.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.41867\n",
      "INFO:tensorflow:step = 17201, loss = 0.000383952 (10.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.43738\n",
      "INFO:tensorflow:step = 17301, loss = 0.00107236 (10.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.43031\n",
      "INFO:tensorflow:step = 17401, loss = 0.134968 (10.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.43698\n",
      "INFO:tensorflow:step = 17501, loss = 0.00340402 (10.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.41526\n",
      "INFO:tensorflow:step = 17601, loss = 0.00375195 (10.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.39918\n",
      "INFO:tensorflow:step = 17701, loss = 0.078675 (10.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.36838\n",
      "INFO:tensorflow:step = 17801, loss = 0.000226596 (10.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34292\n",
      "INFO:tensorflow:step = 17901, loss = 0.00926853 (10.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.41227\n",
      "INFO:tensorflow:step = 18001, loss = 0.00504758 (10.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.41648\n",
      "INFO:tensorflow:step = 18101, loss = 0.0838408 (10.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.42444\n",
      "INFO:tensorflow:step = 18201, loss = 0.0440442 (10.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.32396\n",
      "INFO:tensorflow:step = 18301, loss = 0.0732367 (10.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33562\n",
      "INFO:tensorflow:step = 18401, loss = 0.0153997 (10.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.32944\n",
      "INFO:tensorflow:step = 18501, loss = 0.262021 (10.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33375\n",
      "INFO:tensorflow:step = 18601, loss = 0.000948491 (10.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33004\n",
      "INFO:tensorflow:step = 18701, loss = 0.000351431 (10.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33548\n",
      "INFO:tensorflow:step = 18801, loss = 0.00100313 (10.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.38654\n",
      "INFO:tensorflow:step = 18901, loss = 0.0127767 (10.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.42853\n",
      "INFO:tensorflow:step = 19001, loss = 0.0451503 (10.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.42521\n",
      "INFO:tensorflow:step = 19101, loss = 0.00164932 (10.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.42583\n",
      "INFO:tensorflow:step = 19201, loss = 0.0100778 (10.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.35278\n",
      "INFO:tensorflow:step = 19301, loss = 0.00259067 (10.693 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33672\n",
      "INFO:tensorflow:step = 19401, loss = 0.00723424 (10.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33261\n",
      "INFO:tensorflow:step = 19501, loss = 0.00425639 (10.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34346\n",
      "INFO:tensorflow:step = 19601, loss = 0.0752581 (10.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.36462\n",
      "INFO:tensorflow:step = 19701, loss = 0.0504521 (10.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34421\n",
      "INFO:tensorflow:step = 19801, loss = 0.00423563 (10.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33929\n",
      "INFO:tensorflow:step = 19901, loss = 0.0299212 (10.707 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into E:/tmp/my_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.109075.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x217d8fad198>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "train_input_fun = tf.estimator.inputs.numpy_input_fn(\n",
    "                            x={'X': X_train.astype(np.float32)}, \n",
    "                            y=y_train, batch_size=100, \n",
    "                            num_epochs=None, shuffle=True)\n",
    "cnn_model.train(input_fn=train_input_fun, steps=20000, hooks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-01-01-17:47:57\n",
      "INFO:tensorflow:Restoring parameters from E:/tmp/my_model\\model.ckpt-20000\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-01-17:47:58\n",
      "INFO:tensorflow:Saving dict for global step 20000: accuracy = 0.824, global_step = 20000, loss = 1.6192\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "{'global_step': 20000, 'accuracy': 0.824, 'loss': 1.6192037}\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "                            x={'X': X_val.astype(np.float32)}, \n",
    "                            y=y_val, num_epochs=1, shuffle=False)\n",
    "eval_results = cnn_model.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
